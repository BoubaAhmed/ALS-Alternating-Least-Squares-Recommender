# ALS vs SVD - SystÃ¨mes de Recommandation MovieLens

Un projet acadÃ©mique comparatif implÃ©mentant **Alternating Least Squares (ALS)** et **Singular Value Decomposition (SVD)** pour les systÃ¨mes de recommandation sur le dataset MovieLens 1M.

## ğŸ“‹ Ã€ Propos

Ce projet explore deux algorithmes fondamentaux de recommandation collaborative :

- **ALS** : ImplÃ©mentation personnalisÃ©e avec early stopping, optimisation itÃ©rative, et rÃ©gularisation
- **SVD** : ImplÃ©mentation via la bibliothÃ¨que Surprise avec comparaison directe

### Objectifs du Projet

âœ… ImplÃ©menter ALS from scratch avec optimisation avancÃ©e  
âœ… Comparer les performances avec SVD de rÃ©fÃ©rence  
âœ… Analyser les facteurs latents et l'espace des reprÃ©sentations  
âœ… Ã‰valuer avec des mÃ©triques de ranking (Precision@k, Recall@k, NDCG@k)  
âœ… Fournir une analyse approfondie du comportement des deux modÃ¨les

---

## ğŸ¯ Auteurs

- **Mohamed LKHALIDI**
- **Ahmed BOUBA**

**Institution** : Master Intelligent Systems, UniversitÃ© Moulay Ismail  
**Date** : Novembre 2025  
**Contexte** : Cours "SystÃ¨mes de Recommandation et Blockchain"

---

## ğŸ“ Structure du Projet

```
als-vs-svd-movies1m/
â”œâ”€â”€ als-vs-svd-movies1m.ipynb          # Notebook Jupyter principal
â”œâ”€â”€ rapport_ALS.pdf                     # Rapport dÃ©taillÃ© (PDF)
â”œâ”€â”€ README.md                           # Ce fichier
â”œâ”€â”€ .gitignore                          # Configuration Git
â”œâ”€â”€ requirements.txt                    # DÃ©pendances Python
â”œâ”€â”€ LICENSE                             # Licence du projet
â””â”€â”€ PPT/
    â”œâ”€â”€ PPT_ALS_Systemes_de_recommandation (5).pdf
    â”œâ”€â”€ PPT_ALS_Systemes_de_recommandation (8).pdf
    â””â”€â”€ [prÃ©sentations supplÃ©mentaires]
```

---

## ğŸš€ Installation et Configuration

### PrÃ©requis

- Python 3.8+
- pip ou conda
- Jupyter Notebook

### Ã‰tapes d'Installation

1. **Cloner le repository**

```bash
git clone https://github.com/BoubaAhmed/ALS-Alternating-Least-Squares-Recommender.git
cd ALS-Alternating-Least-Squares-Recommender
```

2. **CrÃ©er un environnement virtuel** (optionnel mais recommandÃ©)

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

3. **Installer les dÃ©pendances**

```bash
pip install -r requirements.txt
```

4. **Lancer le notebook Jupyter**

```bash
jupyter notebook als-vs-svd-movies1m.ipynb
```

---

## ğŸ“Š Dataset

**MovieLens 1M** - TÃ©lÃ©chargement automatique via Kaggle

### CaractÃ©ristiques

- **6,040 utilisateurs**
- **3,706 films**
- **1,000,209 notes** (Ã©chelle 1-5)
- **SparsitÃ© : ~95.64%**
- **DensitÃ© : ~4.36%**

### Fichiers UtilisÃ©s

- `ratings.dat` : Combinaison UserID, MovieID, Rating
- `movies.dat` : MÃ©tadonnÃ©es des films (titres, genres)
- `users.dat` : Informations utilisateurs (Ã¢ge, genre, occupation)

---

## ğŸ§  MÃ©thodologie

### 1. PrÃ©traitement des DonnÃ©es

- **Normalisation** : Conversion des notes 1-5 â†’ 0-1
- **Matrices Creuses** : Utilisation de CSR (Compressed Sparse Row) pour l'efficacitÃ© mÃ©moire
- **Split Train/Test** : 75% train / 25% test, prÃ©servant la structure par utilisateur

### 2. ImplÃ©mentation ALS

#### Algorithme

```
Pour chaque itÃ©ration:
  1. Optimiser les vecteurs utilisateurs (rÃ©solution systÃ¨me linÃ©aire)
  2. Optimiser les vecteurs items (rÃ©solution systÃ¨me linÃ©aire)
  3. Ã‰valuer RMSE/MAE sur validation
  4. Appliquer early stopping si pas d'amÃ©lioration
```

#### CaractÃ©ristiques AvancÃ©es

- **Early Stopping** : ArrÃªt automatique aprÃ¨s 5 itÃ©rations sans amÃ©lioration
- **RÃ©gularisation L2** : Î» = 1.1 pour Ã©viter l'overfitting
- **Optimisation VectorisÃ©e** : Calculs batch pour les Ã©valuations
- **Tolerance** : Îµ = 1e-4 pour convergence

### 3. Algorithme SVD (Surprise)

- **Factorisation de matrices** via descente de gradient
- **Facteurs latents** : 10 dimensions
- **Learning rate** : 0.005
- **Epochs** : 30 itÃ©rations

### 4. Split des DonnÃ©es

```
Dataset original (1M ratings)
    â†“
Train (75%) + Test (25%)
    â†“
Train â†’ Train split (90%) + Validation (10%)
    â†“
EntraÃ®nement ALS avec early stopping
```

---

## ğŸ“ˆ RÃ©sultats

### Performances Quantitatives

| ModÃ¨le  | RMSE   | MAE    | PrÃ©cision@10 | Recall@10 | NDCG@10 | Coverage@10 |
| ------- | ------ | ------ | ------------ | --------- | ------- | ----------- |
| **ALS** | 0.3842 | 0.2567 | 0.4521       | 0.3642    | 0.6234  | 0.8945      |
| **SVD** | 0.3915 | 0.2614 | 0.4389       | 0.3521    | 0.6105  | 0.8876      |

### Conclusions

âœ… **ALS lÃ©gÃ¨rement supÃ©rieur** en RMSE et mÃ©triques de ranking  
âœ… **Convergence rapide** : early stopping actif aprÃ¨s ~8 itÃ©rations  
âœ… **Coverage excellente** : 89%+ du catalogue recommandÃ©  
âœ… **Gain temps** : ~73% d'Ã©conomies avec early stopping

---

## ğŸ“Š Analyse des Facteurs Latents

### Visualisation PCA 2D

- RÃ©duction de 10 dimensions â†’ 2 dimensions principales
- Coloration par genre de film
- Variance expliquÃ©e : ~62%
- RÃ©vÃ¨le les clusters de films similaires

### InterprÃ©tations

- Films du mÃªme genre se groupent naturellement
- Les facteurs latents capturent les prÃ©fÃ©rences utilisateurs
- Structure cohÃ©rente confirmant l'apprentissage efficace

---

## ğŸ” MÃ©triques d'Ã‰valuation

### MÃ©triques UtilisÃ©es

1. **RMSE** (Root Mean Square Error)

   - Mesure globale de prÃ©cision
   - Sensible aux grosses erreurs
   - Ã‰chelle normalisÃ©e 0-1

2. **MAE** (Mean Absolute Error)

   - Erreur moyenne absolue
   - InterprÃ©tation directe en notes 1-5

3. **Precision@k**

   - Proportion de recommandations pertinentes
   - k=10 : top-10 recommandations

4. **Recall@k**

   - CapacitÃ© Ã  retrouver tous les items pertinents
   - Important pour la complÃ©tude

5. **NDCG@k** (Normalized Discounted Cumulative Gain)

   - QualitÃ© du ranking
   - RÃ©compense les items pertinents en haut de liste
   - Normalisation pour comparabilitÃ©

6. **Coverage@k**
   - Pourcentage du catalogue utilisÃ©
   - DiversitÃ© des recommandations

---

## ğŸ’» Utilisation

### Faire des Recommandations

```python
# Charger le modÃ¨le entraÃ®nÃ©
model = ALSRecommender(n_factors=10, lambda_reg=1.1)
model.fit(train_matrix, validation_matrix=val_matrix)

# Obtenir 10 recommandations pour l'utilisateur 100
recs = model.recommend_for_user(user_id=100, n_recommendations=10)
for item_id, pred_score in recs:
    print(f"Item {item_id}: Score prÃ©dite {pred_score:.2f}")
```

### Ã‰valuer le ModÃ¨le

```python
# RMSE sur ensemble de test
test_rmse = model.calculate_rmse(test_matrix)
test_mae = model.calculate_mae(test_matrix)

print(f"Test RMSE: {test_rmse:.4f}")
print(f"Test MAE: {test_mae:.4f}")
```

### Visualiser l'Apprentissage

```python
# Afficher courbes de convergence
model.plot_training_history()
model.plot_combined_training_history()
```

---

## ğŸ“š Contenu du Notebook

Le notebook Jupyter couvre :

1. âœ… Installation et importation des dÃ©pendances
2. âœ… TÃ©lÃ©chargement automatique de MovieLens 1M
3. âœ… Exploration et analyse du dataset
4. âœ… PrÃ©traitement et normalisation
5. âœ… Construction de matrices creuses CSR
6. âœ… Split train/test/validation
7. âœ… **ImplÃ©mentation complÃ¨te d'ALS**
8. âœ… EntraÃ®nement avec early stopping
9. âœ… **ImplÃ©mentation SVD (Surprise)**
10. âœ… Comparaison dÃ©taillÃ©e des deux modÃ¨les
11. âœ… Visualisation des facteurs latents (PCA)
12. âœ… Ã‰valuation multi-critÃ¨res
13. âœ… GÃ©nÃ©ration d'exemples de recommandations
14. âœ… Graphiques comparatifs

---

## ğŸ“– Ressources ComplÃ©mentaires

### Fichiers du Projet

- **`rapport_ALS.pdf`** : Rapport acadÃ©mique dÃ©taillÃ© (17+ pages)

  - Introduction thÃ©orique
  - Formulation mathÃ©matique complÃ¨te
  - RÃ©sultats expÃ©rimentaux
  - Conclusion et perspectives

- **`PPT/`** : PrÃ©sentations PowerPoint
  - Slides de synthÃ¨se du projet
  - Illustrations visuelles
  - RÃ©sultats clÃ©s

---

## ğŸ“ Concepts ClÃ©s

### Factorisation de Matrices

La factorisation vise Ã  dÃ©composer la matrice utilisateurÃ—item R :

R â‰ˆ U Ã— V^T

OÃ¹ :

- **U** : Matrice utilisateurs (m Ã— k)
- **V** : Matrice items (n Ã— k)
- **k** : Nombre de facteurs latents

### Optimisation ALS

Pour chaque facteur, rÃ©soudre le systÃ¨me linÃ©aire :

(V^T V + Î»I) u_i = V^T r_i

### Early Stopping

- Monitorer RMSE de validation
- ArrÃªter si pas d'amÃ©lioration pendant N itÃ©rations
- Restaurer les meilleurs paramÃ¨tres

---

## âš™ï¸ HyperparamÃ¨tres

### Configuration Optimale ALS

```python
n_factors = 10              # Dimensions latentes
lambda_reg = 1.1            # RÃ©gularisation L2
n_iterations = 30           # Maximum d'itÃ©rations
early_stopping_rounds = 5   # Patience early stopping
tolerance = 1e-4           # Seuil d'amÃ©lioration
```

### Configuration SVD

```python
n_factors = 10
n_epochs = 30
lr_all = 0.005            # Learning rate
reg_all = 1.1             # RÃ©gularisation
```

---

## ğŸ”§ DÃ©pendances

```
numpy>=1.21.0
pandas>=1.3.0
scipy>=1.7.0
scikit-learn>=0.24.0
matplotlib>=3.4.0
scikit-surprise>=1.1.0
implicit>=0.5.2
kagglehub>=0.1.0
```

Installation via `requirements.txt` fourni.

---

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir `LICENSE` pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

- MovieLens pour le dataset
- BibliothÃ¨que Surprise pour l'implÃ©mentation SVD de rÃ©fÃ©rence
- UniversitÃ© Moulay Ismail pour le contexte acadÃ©mique

---

## ğŸ“ Contact

Pour des questions sur le projet :

- **GitHub Issues** : Utiliser le systÃ¨me d'issues du repository

---

## ğŸ”® AmÃ©liorations Futures

- [ ] ParallÃ©lisation des calculs ALS
- [ ] Support des GPU pour les matrices volumineuses
- [ ] API REST pour les recommandations en temps rÃ©el
- [ ] Interface web avec Streamlit/Flask
- [ ] IntÃ©gration de donnÃ©es auxiliaires (contenu films)
- [ ] Ã‰valuation cross-validation k-fold
- [ ] Optimisation des hyperparamÃ¨tres (grid search)

---

**DerniÃ¨re mise Ã  jour** : Novembre 2025
